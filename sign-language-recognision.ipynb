{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# References\n",
    "\n",
    "https://www.kaggle.com/code/moritzkronberger/snn-0-94-acc/notebook\n",
    "https://towardsdatascience.com/sign-language-recognition-with-advanced-computer-vision-7b74f20f3442\n",
    "https://github.com/mg343/Sign-Language-Detection/blob/main/camerahands.py"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "retrain = False\n",
    "\n",
    "\n",
    "train_df = pd.read_csv(\"data/sign_mnist_train.csv\")\n",
    "test_df = pd.read_csv(\"data/sign_mnist_test.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_train = train_df['label']\n",
    "y_test = test_df['label']\n",
    "del train_df['label']\n",
    "del test_df['label']"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "label_binarizer = LabelBinarizer()\n",
    "y_train = label_binarizer.fit_transform(y_train)\n",
    "y_test = label_binarizer.fit_transform(y_test)\n",
    "\n",
    "x_train = train_df.values\n",
    "x_test = test_df.values\n",
    "\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "x_train = x_train.reshape(-1,28,28,1)\n",
    "x_test = x_test.reshape(-1,28,28,1)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    zoom_range = 0.1, # Randomly zoom image\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=False,  # randomly flip images\n",
    "    vertical_flip=False)  # randomly flip images\n",
    "\n",
    "datagen.fit(x_train)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(75 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu' , input_shape = (28,28,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Conv2D(50 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Conv2D(25 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units = 512 , activation = 'relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units = 24 , activation = 'softmax'))\n",
    "model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429/429 [==============================] - 49s 113ms/step - loss: 0.8562 - accuracy: 0.7301 - val_loss: 1.7357 - val_accuracy: 0.5031 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "429/429 [==============================] - 20s 47ms/step - loss: 0.1775 - accuracy: 0.9397 - val_loss: 0.1322 - val_accuracy: 0.9551 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "429/429 [==============================] - 20s 46ms/step - loss: 0.0873 - accuracy: 0.9727 - val_loss: 0.0230 - val_accuracy: 0.9964 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "429/429 [==============================] - 20s 48ms/step - loss: 0.0605 - accuracy: 0.9803 - val_loss: 0.0186 - val_accuracy: 0.9961 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "429/429 [==============================] - ETA: 0s - loss: 0.0579 - accuracy: 0.9811\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "429/429 [==============================] - 21s 48ms/step - loss: 0.0579 - accuracy: 0.9811 - val_loss: 0.0693 - val_accuracy: 0.9748 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "429/429 [==============================] - 22s 51ms/step - loss: 0.0217 - accuracy: 0.9932 - val_loss: 0.0090 - val_accuracy: 0.9989 - lr: 5.0000e-04\n",
      "Epoch 7/50\n",
      "425/429 [============================>.] - ETA: 0s - loss: 0.0142 - accuracy: 0.9959"
     ]
    }
   ],
   "source": [
    "if retrain:\n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 2, verbose=1,factor=0.5, min_lr=0.00001)\n",
    "    history = model.fit(datagen.flow(x_train,y_train, batch_size = 128) ,epochs = 20 , validation_data = (x_test, y_test) , callbacks = [learning_rate_reduction])\n",
    "    model.save('smnist.h5')\n",
    "else:\n",
    "    model = load_model('smnist.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "amount_of_samples = 12\n",
    "\n",
    "# Pick 10 random images for test data set\n",
    "random.seed(3) # to make this deterministic\n",
    "sample_indexes = random.sample(range(len(x_test)), amount_of_samples)\n",
    "sample_images = [x_test[i] for i in sample_indexes]\n",
    "sample_labels = [y_test[i] for i in sample_indexes]\n",
    "\n",
    "ground_truth = np.argmax(sample_labels, axis=1)\n",
    "\n",
    "X_sample = np.array(sample_images)\n",
    "prediction = model.predict(X_sample)\n",
    "predicted_categories = np.argmax(prediction, axis=1)\n",
    "predicted_categories"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Display the predictions and the ground truth visually.\n",
    "\n",
    "def display_prediction (images, true_labels, predicted_labels):\n",
    "    fig = plt.figure(figsize=(20, amount_of_samples +10))\n",
    "    for i in range(len(true_labels)):\n",
    "        truth = true_labels[i]\n",
    "        prediction = predicted_labels[i]\n",
    "        plt.subplot(amount_of_samples, 4,1+i)\n",
    "        plt.axis('off')\n",
    "        color='green' if truth == prediction else 'red'\n",
    "        plt.text(30, 10, \"Truth:        {0}\\nPrediction: {1}\".format(truth, prediction),\n",
    "                 fontsize=12, color=color)\n",
    "        plt.imshow(images[i])\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display_prediction(sample_images, ground_truth, predicted_categories)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ground_truth, predicted_categories"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# German Sign Language Recognition"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "german_data = pd.read_csv(\"data/german/german_sign_language.csv\")\n",
    "label_enc = german_data.label.unique()\n",
    "german_data.label = german_data.label.replace(label_enc, list(range(0,24)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ds_y = german_data.label.array\n",
    "ds_y = pd.factorize(ds_y)[0]\n",
    "ds_y = np.array(ds_y)\n",
    "\n",
    "ds_x = german_data.drop(['label'], axis=1)\n",
    "ds_x = ds_x.to_numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_samples = len(german_data)\n",
    "classes = pd.unique(german_data.label)\n",
    "print(f'Samples: {num_samples}')\n",
    "print(f'Classes: {classes}')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(ds_y.shape)\n",
    "print(ds_x.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_samples = ds_x.shape[0]\n",
    "dim = 3\n",
    "landmarks = 21 # Orignal 21\n",
    "test = 10\n",
    "ds_x = ds_x.reshape((num_samples, landmarks, dim))\n",
    "print(ds_x.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(ds_x, ds_y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num = 10\n",
    "example = ds_x[num]\n",
    "label = ds_y[num]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "for vec in example:\n",
    "    ax.scatter(vec[0], vec[2], vec[1], color='b')\n",
    "\n",
    "plt.title(f'Label: {classes[label]}')\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Z')\n",
    "ax.set_zlabel('Y')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "epochs = 10\n",
    "val_split = .2\n",
    "\n",
    "# labels to one hot\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train.astype(int))\n",
    "y_test = to_categorical(y_test.astype(int))\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# create callbacks\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_acc',\n",
    "                           restore_best_weights=True,\n",
    "                           patience=10,\n",
    "                           verbose=0)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_acc',\n",
    "                              factor=0.2,\n",
    "                              min_lr=0.00001,\n",
    "                              patience=5,\n",
    "                              verbose=0)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras import Input, Model\n",
    "from keras.layers import Dense, Flatten, AlphaDropout, LayerNormalization\n",
    "\n",
    "inputs = Input(shape=x_train[0].shape, name='Landmark_Vectors')\n",
    "\n",
    "layerNorm = LayerNormalization(name='LayerNorm')(inputs)\n",
    "\n",
    "flatten = Flatten(name='Flatten_Vectors')(layerNorm)\n",
    "\n",
    "dense_count = 6\n",
    "dense_base = 48\n",
    "out = flatten\n",
    "\n",
    "for i in range(dense_count):\n",
    "    units = (dense_count-i) * (dense_count-i) * dense_base\n",
    "    dense = Dense(units,\n",
    "                  kernel_initializer=\"lecun_normal\",\n",
    "                  bias_initializer=\"zeros\",\n",
    "                  activation='selu',\n",
    "                  name=f'Dense_{i+1}')\n",
    "    a_dropout = AlphaDropout(0.05, name=f'Dropout_{i+1}')\n",
    "    out = dense(out)\n",
    "    out = a_dropout(out)\n",
    "\n",
    "outputs = Dense(y_train[0].shape[0], activation='softmax', name='Output_Vector')(out)\n",
    "model = Model(inputs=inputs, outputs=outputs, name=\"SNN_6\")\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "retrain = False\n",
    "if retrain:\n",
    "    adam = Adam(learning_rate=0.001, beta_2=0.99, epsilon=0.01)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer=adam,\n",
    "                      metrics=['acc'])\n",
    "\n",
    "    history = model.fit(x_train, y_train,\n",
    "                            epochs=500,\n",
    "                            batch_size=16,\n",
    "                            validation_split=val_split,\n",
    "                            callbacks=[early_stop, reduce_lr])\n",
    "\n",
    "    model.save(\"german_dataset.h5\")\n",
    "    history = pd.DataFrame(history.history)\n",
    "    history.to_csv(\"german_history.csv\")\n",
    "else:\n",
    "    model = load_model(\"german_dataset.h5\")\n",
    "    history = pd.read_csv(\"german_history.csv\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(history['loss'], label='train loss')\n",
    "plt.plot(history['val_loss'], label='val loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(history['acc'], label='train acc')\n",
    "plt.plot(history['val_acc'], label='val acc')\n",
    "plt.legend()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f'*'*11 + \"Test data\" + 11*\"*\" +f\"\\nloss={loss:.4f} acc={acc:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)\n",
    "prediction_classes = np.argmax(predictions, axis=-1)\n",
    "\n",
    "gt_classes = np.argmax(y_test, axis=-1)\n",
    "confusion_matrix = metrics.confusion_matrix(gt_classes, prediction_classes)\n",
    "\n",
    "sns.heatmap(pd.DataFrame(confusion_matrix, index=classes, columns=classes), annot=True, cmap=\"YlGnBu\", fmt='d')\n",
    "plt.tight_layout()\n",
    "plt.title('confusion matrix - ' + model.name, y=1.1)\n",
    "plt.ylabel('predicted')\n",
    "plt.xlabel('ground truth')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "amount_of_samples = 12\n",
    "\n",
    "# Pick 10 random images for test data set\n",
    "random.seed(3) # to make this deterministic\n",
    "sample_indexes = random.sample(range(len(x_test)), amount_of_samples)\n",
    "sample_images = [x_test[i] for i in sample_indexes]\n",
    "sample_labels = [y_test[i] for i in sample_indexes]\n",
    "\n",
    "ground_truth = np.argmax(sample_labels, axis=1)\n",
    "\n",
    "X_sample = np.array(sample_images)\n",
    "prediction = model.predict(X_sample)\n",
    "predicted_categories = np.argmax(prediction, axis=1)\n",
    "predicted_categories, ground_truth"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
