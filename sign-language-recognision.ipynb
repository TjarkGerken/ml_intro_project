{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"data/sign_mnist_train.csv\")\n",
    "test_df = pd.read_csv(\"data/sign_mnist_test.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_train = train_df['label']\n",
    "y_test = test_df['label']\n",
    "del train_df['label']\n",
    "del test_df['label']\n",
    "\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_train = label_binarizer.fit_transform(y_train)\n",
    "y_test = label_binarizer.fit_transform(y_test)\n",
    "\n",
    "x_train = train_df.values\n",
    "x_test = test_df.values\n",
    "\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "x_train = x_train.reshape(-1,28,28,1)\n",
    "x_test = x_test.reshape(-1,28,28,1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    zoom_range = 0.1, # Randomly zoom image\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=False,  # randomly flip images\n",
    "    vertical_flip=False)  # randomly flip images\n",
    "\n",
    "datagen.fit(x_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(75 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu' , input_shape = (28,28,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Conv2D(50 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Conv2D(25 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units = 512 , activation = 'relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units = 24 , activation = 'softmax'))\n",
    "model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-05-01T13:47:34.658635Z",
     "end_time": "2023-05-01T13:54:26.904479Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:47:34.674120: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 75)        750       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 28, 28, 75)       300       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 75)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 50)        33800     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 14, 14, 50)        0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 14, 14, 50)       200       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 50)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 7, 7, 25)          11275     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 7, 7, 25)         100       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 4, 25)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 400)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               205312    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 24)                12312     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 264,049\n",
      "Trainable params: 263,749\n",
      "Non-trainable params: 300\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 13:47:39.153634: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "215/215 [==============================] - 20s 91ms/step - loss: 1.0879 - accuracy: 0.6617 - val_loss: 3.8524 - val_accuracy: 0.0958 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "215/215 [==============================] - 20s 94ms/step - loss: 0.2075 - accuracy: 0.9328 - val_loss: 1.3424 - val_accuracy: 0.5672 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "215/215 [==============================] - 20s 94ms/step - loss: 0.1038 - accuracy: 0.9666 - val_loss: 0.1548 - val_accuracy: 0.9525 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "215/215 [==============================] - 21s 96ms/step - loss: 0.0612 - accuracy: 0.9807 - val_loss: 0.0193 - val_accuracy: 0.9947 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "215/215 [==============================] - 23s 107ms/step - loss: 0.0462 - accuracy: 0.9859 - val_loss: 0.1771 - val_accuracy: 0.9398 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "215/215 [==============================] - ETA: 0s - loss: 0.0372 - accuracy: 0.9877\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "215/215 [==============================] - 20s 95ms/step - loss: 0.0372 - accuracy: 0.9877 - val_loss: 0.0353 - val_accuracy: 0.9884 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "215/215 [==============================] - 19s 88ms/step - loss: 0.0211 - accuracy: 0.9941 - val_loss: 0.0060 - val_accuracy: 0.9983 - lr: 5.0000e-04\n",
      "Epoch 8/20\n",
      "215/215 [==============================] - 19s 88ms/step - loss: 0.0165 - accuracy: 0.9950 - val_loss: 0.0033 - val_accuracy: 0.9999 - lr: 5.0000e-04\n",
      "Epoch 9/20\n",
      "215/215 [==============================] - 20s 91ms/step - loss: 0.0129 - accuracy: 0.9966 - val_loss: 0.0822 - val_accuracy: 0.9741 - lr: 5.0000e-04\n",
      "Epoch 10/20\n",
      "215/215 [==============================] - ETA: 0s - loss: 0.0128 - accuracy: 0.9964\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "215/215 [==============================] - 20s 91ms/step - loss: 0.0128 - accuracy: 0.9964 - val_loss: 0.0039 - val_accuracy: 0.9985 - lr: 5.0000e-04\n",
      "Epoch 11/20\n",
      "215/215 [==============================] - 19s 89ms/step - loss: 0.0098 - accuracy: 0.9971 - val_loss: 0.0013 - val_accuracy: 0.9999 - lr: 2.5000e-04\n",
      "Epoch 12/20\n",
      "215/215 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 0.9974\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "215/215 [==============================] - 19s 89ms/step - loss: 0.0091 - accuracy: 0.9974 - val_loss: 0.0020 - val_accuracy: 0.9999 - lr: 2.5000e-04\n",
      "Epoch 13/20\n",
      "215/215 [==============================] - 21s 95ms/step - loss: 0.0077 - accuracy: 0.9979 - val_loss: 0.0020 - val_accuracy: 0.9999 - lr: 1.2500e-04\n",
      "Epoch 14/20\n",
      "215/215 [==============================] - 19s 88ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 9.7145e-04 - val_accuracy: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 15/20\n",
      "215/215 [==============================] - 19s 87ms/step - loss: 0.0056 - accuracy: 0.9987 - val_loss: 0.0011 - val_accuracy: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 16/20\n",
      "215/215 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 0.9988\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "215/215 [==============================] - 21s 99ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 7.9405e-04 - val_accuracy: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 17/20\n",
      "215/215 [==============================] - 19s 89ms/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 8.1902e-04 - val_accuracy: 1.0000 - lr: 6.2500e-05\n",
      "Epoch 18/20\n",
      "215/215 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 0.9991\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "215/215 [==============================] - 22s 103ms/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 4.2711e-04 - val_accuracy: 1.0000 - lr: 6.2500e-05\n",
      "Epoch 19/20\n",
      "215/215 [==============================] - 19s 86ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 5.1693e-04 - val_accuracy: 1.0000 - lr: 3.1250e-05\n",
      "Epoch 20/20\n",
      "215/215 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 0.9990\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "215/215 [==============================] - 28s 129ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 5.8003e-04 - val_accuracy: 1.0000 - lr: 3.1250e-05\n"
     ]
    }
   ],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 2, verbose=1,factor=0.5, min_lr=0.00001)\n",
    "history = model.fit(datagen.flow(x_train,y_train, batch_size = 128) ,epochs = 20 , validation_data = (x_test, y_test) , callbacks = [learning_rate_reduction])\n",
    "\n",
    "model.save('smnist.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 75)        750       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 28, 28, 75)       300       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 75)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 50)        33800     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 14, 14, 50)        0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 14, 14, 50)       200       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 50)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 7, 7, 25)          11275     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 7, 7, 25)         100       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 4, 25)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 400)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               205312    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 24)                12312     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 264,049\n",
      "Trainable params: 263,749\n",
      "Non-trainable params: 300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T14:21:00.302182Z",
     "end_time": "2023-05-01T14:21:00.341073Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 9ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([14, 12,  1, 19, 15, 22, 20, 22, 13, 17,  3, 13,  1,  4,  5, 11, 21,\n       14,  4,  0, 14, 18,  6,  6, 12, 10, 23,  4,  2, 12, 17, 23, 23, 20,\n       12, 11,  7, 22, 17,  3, 17,  6,  1, 22,  4, 23,  4,  6, 20, 14, 17,\n       21,  5, 11,  2,  6, 15,  9,  1,  4, 20,  4, 23, 11,  1,  1,  8,  5,\n        6, 11,  7,  7,  7,  3,  5, 20, 20,  7,  9, 18,  6, 21,  6,  4, 20,\n       16, 15, 20,  5, 11,  6, 13,  7, 10,  4,  5, 18,  7, 19, 20,  5,  8,\n       23,  2, 14, 21,  6, 15, 20, 20,  0,  8,  9,  4,  4, 23, 14,  4,  5,\n       14,  1, 18, 17, 23, 13,  4, 20,  3,  9, 11,  7,  1,  9, 10,  9,  4,\n       14,  3,  3,  0, 13,  2, 11, 21,  1,  4, 14, 22, 18,  7, 16, 12, 23,\n        6,  6, 18, 14,  6,  4,  8, 20,  9, 13, 18, 10,  8,  7, 11,  4, 15,\n       11,  3, 14, 20, 11,  1,  0, 15, 14, 13,  0, 18, 10, 23,  7,  3, 12,\n       20,  3, 22,  1,  4, 12,  7, 13,  3,  1,  3,  0,  8,  9,  0, 23, 13,\n       12,  9,  9, 20,  2, 11, 14, 15, 16, 23,  9,  3,  9, 17,  1,  1,  9,\n       19, 20,  0,  4, 11,  0, 14,  0,  0, 22,  1,  7,  1, 18, 11,  4,  4,\n       11, 16,  1,  0, 11, 12, 17, 23, 12,  5,  0,  7, 15,  8,  4, 22,  1,\n        7, 22, 20, 14, 12, 16,  4,  1, 18,  2,  7,  1,  9, 14, 20,  9,  2,\n       18,  7, 16, 21, 11,  6,  5,  8, 16,  6, 17,  7, 21, 21, 23,  9, 22,\n        1,  9,  7,  1, 12, 17, 17, 21,  5, 16,  1,  8, 18,  8,  7,  3, 14,\n       21, 17, 11,  7,  2, 17,  1, 12, 23, 18, 17,  0,  5,  8, 19,  1, 23,\n       12,  1, 15, 12, 10, 23, 14,  9,  4,  6,  1, 19, 16,  3, 14, 11, 13,\n       14, 11, 13, 23,  6, 22, 17, 22, 22,  7, 17,  9,  9,  4, 21, 14, 10,\n        9,  4,  2, 11,  8,  7,  1,  5, 11, 11,  6, 12,  5,  2, 17,  3,  6,\n        0, 21, 18,  7, 20,  0,  7,  4,  8, 11,  2,  7,  2, 14, 12, 14, 13,\n        2, 23,  4, 13, 14, 23,  5,  1, 16, 13, 22,  5,  9, 22, 14,  1,  2,\n        7, 12, 11, 23, 13,  9, 20, 10,  5, 13,  9,  2,  1, 14, 20, 18,  9,\n        8, 19, 13,  7, 19, 21,  5, 14,  7, 10, 19, 21,  5, 13,  1,  9,  6,\n       23,  7,  0, 20,  0,  8,  4, 12, 23, 23,  7, 20,  4, 22,  7, 13, 10,\n        6, 23, 12, 16, 13,  0, 11,  7, 17, 23, 17, 23, 22, 21,  1, 15,  1,\n       11, 15, 21, 16, 22,  3, 11,  1, 16, 11, 13, 20,  9,  1, 20, 20,  1,\n        5, 11, 22, 13,  4,  7, 19])"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "model = load_model('smnist.h5')\n",
    "\n",
    "\n",
    "amount_of_samples = 500\n",
    "\n",
    "# Pick 10 random images for test data set\n",
    "random.seed(3) # to make this deterministic\n",
    "sample_indexes = random.sample(range(len(x_test)), amount_of_samples)\n",
    "sample_images = [x_test[i] for i in sample_indexes]\n",
    "sample_labels = [y_test[i] for i in sample_indexes]\n",
    "\n",
    "ground_truth = np.argmax(sample_labels, axis=1)\n",
    "\n",
    "X_sample = np.array(sample_images)\n",
    "prediction = model.predict(X_sample)\n",
    "predicted_categories = np.argmax(prediction, axis=1)\n",
    "predicted_categories"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T14:08:05.675335Z",
     "end_time": "2023-05-01T14:08:06.163731Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "# Display the predictions and the ground truth visually.\n",
    "def display_prediction (images, true_labels, predicted_labels):\n",
    "    fig = plt.figure(figsize=(20, amount_of_samples +10))\n",
    "    for i in range(len(true_labels)):\n",
    "        truth = true_labels[i]\n",
    "        prediction = predicted_labels[i]\n",
    "        plt.subplot(amount_of_samples, 4,1+i)\n",
    "        plt.axis('off')\n",
    "        color='green' if truth == prediction else 'red'\n",
    "        plt.text(30, 10, \"Truth:        {0}\\nPrediction: {1}\".format(truth, prediction),\n",
    "                 fontsize=12, color=color)\n",
    "        plt.imshow(images[i])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T14:23:17.045587Z",
     "end_time": "2023-05-01T14:23:17.049580Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display_prediction(sample_images, ground_truth, predicted_categories)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T14:14:11.118987Z",
     "end_time": "2023-05-01T14:14:12.410610Z"
    },
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
